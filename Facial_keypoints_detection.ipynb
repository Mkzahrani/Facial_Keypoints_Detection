{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: False\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data\n",
    "import copy\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('GPU available:', use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path2data = '/home/r120084/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path2trainData = path2data + 'train/training.csv'\n",
    "path2testData = path2data + 'test/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceKeyPointsDataset(Dataset):\n",
    "\n",
    "    def __init__(self, path2data, val_size = 0.1, dropnan = True, transforms=None, is_valid=False,\n",
    "                 is_test=False, is_train = False):\n",
    "    \n",
    "        self.df = pd.read_csv(path2data)\n",
    "        if dropnan:\n",
    "             self.drop_nan()\n",
    "                 \n",
    "        self.df['Image'] = self.df['Image'].apply(lambda im: self.get_image(im))\n",
    "        self.X = self.get_X()\n",
    "        \n",
    "        if ( (is_train) or (is_valid)):\n",
    "            self.get_train_target() \n",
    "            if is_valid:\n",
    "                self.split_data(val_size)\n",
    "            self.normalize_target()\n",
    "            \n",
    "        if is_test:\n",
    "            self.get_X()\n",
    "            self.get_test_target()\n",
    "                 \n",
    "    def normalize_target(self):\n",
    "        self.y = (self.y- self.y.max()) /self.y.max()\n",
    "        self.y = self.y.astype(np.float32)\n",
    " \n",
    "    def _show_keys(self):\n",
    "         print(self.df.dtypes)\n",
    "\n",
    "    def get_image(self, x):\n",
    "        x = np.fromstring(x, sep = ' ')\n",
    "        return x\n",
    "\n",
    "    def drop_nan(self):\n",
    "        self.df = self.df.dropna()\n",
    "\n",
    "    def get_X(self):\n",
    "\n",
    "        X = np.vstack(self.df['Image'].values) / 255.  # scale pixel values to [0, 1]\n",
    "        X = X.astype(np.float32)\n",
    "        X = X.reshape(-1, 1, 96, 96) # return each images as 1 x 96 x 96\n",
    "        return X\n",
    "\n",
    "    def get_train_target(self):\n",
    "\n",
    "        self.y = self.df[self.df.columns[:-1]]\n",
    "\n",
    "    def get_test_target(self):\n",
    "        self.y = None\n",
    "\n",
    "    def split_data(self, val_size = 0.1):\n",
    "\n",
    "        np.random.seed(4572)\n",
    "        indices = range(len(self.X))\n",
    "\n",
    "        ind = np.random.permutation(indices)\n",
    "        split = np.round(val_size * len(self.X))\n",
    "        index= np.array(ind[:split])\n",
    "        \n",
    "        self.X = self.X.take(index,axis=0)\n",
    "        self.y = self.y.take(index,axis=0)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = self.X[index]\n",
    "        label = self.y[index]\n",
    "        return image, label\n",
    "    \n",
    "    def __str__(self):\n",
    "        print('Dataset size is {}'.format(self.df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adessowiki/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:58: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "}\n",
    "\n",
    "dsets = {\n",
    "    'train': FaceKeyPointsDataset(path2trainData, transforms=data_transforms['train'], is_train = True),\n",
    "    'valid': FaceKeyPointsDataset(path2trainData, transforms=data_transforms['valid'], is_valid=True, val_size=0.2),\n",
    "    'test':  FaceKeyPointsDataset(path2testData, transforms=data_transforms['valid'], is_test=True),\n",
    "}\n",
    "\n",
    "dset_loaders = {\n",
    "    'train': DataLoader(dsets['train'], batch_size=batch_size, shuffle=True),\n",
    "    'valid': DataLoader(dsets['valid'], batch_size=batch_size, shuffle=False),\n",
    "    'test':  DataLoader(dsets['test'],  batch_size=batch_size, shuffle=False),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_eye_center_x            float64\n",
      "left_eye_center_y            float64\n",
      "right_eye_center_x           float64\n",
      "right_eye_center_y           float64\n",
      "left_eye_inner_corner_x      float64\n",
      "left_eye_inner_corner_y      float64\n",
      "left_eye_outer_corner_x      float64\n",
      "left_eye_outer_corner_y      float64\n",
      "right_eye_inner_corner_x     float64\n",
      "right_eye_inner_corner_y     float64\n",
      "right_eye_outer_corner_x     float64\n",
      "right_eye_outer_corner_y     float64\n",
      "left_eyebrow_inner_end_x     float64\n",
      "left_eyebrow_inner_end_y     float64\n",
      "left_eyebrow_outer_end_x     float64\n",
      "left_eyebrow_outer_end_y     float64\n",
      "right_eyebrow_inner_end_x    float64\n",
      "right_eyebrow_inner_end_y    float64\n",
      "right_eyebrow_outer_end_x    float64\n",
      "right_eyebrow_outer_end_y    float64\n",
      "nose_tip_x                   float64\n",
      "nose_tip_y                   float64\n",
      "mouth_left_corner_x          float64\n",
      "mouth_left_corner_y          float64\n",
      "mouth_right_corner_x         float64\n",
      "mouth_right_corner_y         float64\n",
      "mouth_center_top_lip_x       float64\n",
      "mouth_center_top_lip_y       float64\n",
      "mouth_center_bottom_lip_x    float64\n",
      "mouth_center_bottom_lip_y    float64\n",
      "Image                         object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "dsets['train']._show_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "for i in range(0, 4):\n",
    "    plt.subplot(1,4,i+1)\n",
    "    img = np.squeeze(X_train[i])\n",
    "    cordinates = y_train[i]* 48 + 48\n",
    "    plt.imshow(img, cmap = 'gray')\n",
    "    plt.plot(cordinates[::2], cordinates[1::2], 'o')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train).type(torch.FloatTensor)\n",
    "y_train = torch.from_numpy(y_train).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset,\n",
    "                                          batch_size=8,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_out = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class myconvNet(nn.Module):\n",
    "\n",
    "    def __init__(self, image_size=(1,96,96)):\n",
    "        super(myconvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        \n",
    "        feature_size = self._get_conv_output(image_size)\n",
    "        \n",
    "        self.fc1 = nn.Linear(feature_size, 250)        \n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, nb_out)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self._forward_features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, p=0.25, training=self.training)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def _forward_features(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))       \n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def _get_conv_output(self, shape):\n",
    "        bs = 1\n",
    "        input = Variable(torch.rand(bs, *shape))\n",
    "        output_feat = self._forward_features(input)\n",
    "        n_size = output_feat.data.view(bs, -1).size(1)\n",
    "        return n_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myconvNet = myconvNet()\n",
    "if use_gpu:\n",
    "    myconvNet = myconvNet.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(myconvNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(path2testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
